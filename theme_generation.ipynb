{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD2pAABiWMjD"
      },
      "source": [
        "# Tutorial 4: Theme generation\n",
        "*This notebook is part of the [LLMCode library](https://github.com/PerttuHamalainen/LLMCode).*\n",
        "\n",
        "*A note on data privacy: The user experience of this notebook is better on Google Colab, but if you are processing data that cannot be sent to Google and OpenAI servers, you should run this notebook locally using the \"Aalto\" LLM API.*\n",
        "\n",
        "**Learning goals**\n",
        "\n",
        "In this notebook, you'll learn to utilize LLMs to code qualitative data inductively and deductively, as well as how to evaluate the human-likeness of the output.\n",
        "\n",
        "**How to use this Colab notebook?**\n",
        "* Select the LLM API and model to use below. The default values are recommended, but some of the examples may produce better quality results using the more expensive \"gpt-4o\" model. For details about the models, see [OpenAI documentation](https://platform.openai.com/docs/models).\n",
        "* Select \"Run all\" from the Runtime menu above.\n",
        "* Enter your API key below when prompted. This will be provided to you at the workshop. You can also create your own OpenAI account at https://platform.openai.com/signup. The initial free quota you get with the account should be enough for the exercises of this notebook. To create an API key, follow [OpenAI's instructions](https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key)\n",
        "* Proceed top-down following the instructions\n",
        "\n",
        "**New to Colab notebooks?**\n",
        "\n",
        "Colab notebooks are browser-based learning environments consisting of *cells* that include either text or code. The code is executed in a Google virtual machine instead of your own computer. You can run code cell-by-cell (click the \"play\" symbol of each code cell), and selecting \"Run all\" as instructed above is usually the first step to verify that everything works. For more info, see Google's [Intro video](https://www.youtube.com/watch?v=inN8seMm7UI) and [curated example notebooks](https://colab.google/notebooks/).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QwnAjEXbeCnn"
      },
      "outputs": [],
      "source": [
        "#Initial setup code. If you opened this notebook in Colab, this code is hidden\n",
        "#by default to avoid unnecessary user interface clutter\n",
        "\n",
        "#-------------------------------------------------------\n",
        "#User-defined parameters. You can freely edit the values\n",
        "llm_API=\"OpenAI\" # @param [\"OpenAI\", \"Aalto\"]\n",
        "gpt_model=\"gpt-4o-mini\" #@param [\"gpt-4o-mini\",\"gpt-4o\"]\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "#Implementation. Only edit this part if you know what your are doing\n",
        "\n",
        "#Import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import HTML, Markdown, display, clear_output\n",
        "import getpass\n",
        "import os\n",
        "import html\n",
        "import lxml\n",
        "import re\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import textwrap\n",
        "import random\n",
        "import math\n",
        "from itertools import chain\n",
        "from collections import Counter, defaultdict\n",
        "from google.colab import files\n",
        "\n",
        "original_dir = os.getcwd()\n",
        "\n",
        "#determine if we are running in Colab\n",
        "import sys\n",
        "RunningInCOLAB = 'google.colab' in sys.modules\n",
        "if RunningInCOLAB:\n",
        "  import plotly.io as pio\n",
        "  pio.renderers.default = \"colab\"\n",
        "  if not os.path.exists(\"LLMCode\"):\n",
        "    if not os.getcwd().endswith(\"LLMCode\"):\n",
        "      print(\"Cloning the LLMCode repository...\")\n",
        "      #until the repo is public, we download this working copy instead of cloning\n",
        "      #(shared as: anyone with the link can view)\n",
        "      #!wget \"https://drive.google.com/uc?export=download&id=1ylMQn96JuKBB-YU9mHLyEhtm6Qin1Kgh\" -O LLMCode.zip\n",
        "      #!mkdir LLMCode\n",
        "      #!unzip -q LLMCode.zip -d LLMCode\n",
        "      !git clone https://github.com/PerttuHamalainen/LLMCode.git\n",
        "  if not os.getcwd().endswith(\"LLMCode\"):\n",
        "    os.chdir(\"LLMCode\")\n",
        "    print(\"Installing dependencies...\")\n",
        "    !pip install -r requirements_notebooks.txt\n",
        "import llmcode\n",
        "\n",
        "os.chdir(original_dir)\n",
        "\n",
        "#Jupyter is already running an asyncio event loop => need this hack for async OpenAI API calling\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "#Prompt the user for an API key if not provided via a system variable\n",
        "clear_output()\n",
        "if llm_API==\"OpenAI\":\n",
        "    if os.environ.get(\"OPENAI_API_KEY\") is None:\n",
        "        print(\"Please input an OpenAI API key\")\n",
        "        api_key = getpass.getpass()\n",
        "        os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "elif llm_API==\"Aalto\":\n",
        "    if os.environ.get(\"AALTO_OPENAI_API_KEY\") is None:\n",
        "        print(\"Please input an Aalto OpenAI API key\")\n",
        "        api_key = getpass.getpass()\n",
        "        os.environ[\"AALTO_OPENAI_API_KEY\"] = api_key\n",
        "else:\n",
        "    print(f\"Invalid API type: {llm_API}\")\n",
        "\n",
        "#Initialize the LLMCode library\n",
        "llmcode.init(API=llm_API)\n",
        "llmcode.set_cache_directory(\"data_exploration_cache\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bLvtCkDn2ST"
      },
      "source": [
        "# Themes\n",
        "\n",
        "In this notebook, we use LLMs to group the codes you generated in the previous notebook \"Inductive and deductive coding\" under wider themes, as is often done as part of qualitative analysis.\n",
        "\n",
        "Before we begin, let's take a moment to critically reflect on the role of agency and transparency when using LLMs for this purpose. While LLMs can efficiently organize large amounts of data, they may lack the nuanced understanding of human context and intentions. This raises concerns about researcher agencyâ€”how much control do researchers retain over the interpretation of their data? Similarly, the transparency of LLMs' decision-making processes is limited, making it difficult to trace how specific themes were generated, which may obscure valuable insights or introduce unintended biases. Balancing automation with researcher input is crucial to maintain rigor and interpretive depth in the analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qo9uuka0EPlC"
      },
      "source": [
        "# Loading the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J82_9Dzz1fdw"
      },
      "source": [
        "For this notebook, you may choose to use the codes you generated in the previous notebook, or use a set of codes we have generated based on the [Games As Art](https://osf.io/ryvt6/) survey dataset. If you wish to use these default codes, run the following code with the default inputs.\n",
        "\n",
        "**Loading your own codes**\n",
        "\n",
        "To use your own codes, choose one of the `coded_texts` .csv files you created in the previous notebook. You may choose to use the codes from any of the three methods (inductive, inductive with code consistency, deductive) explored in the previous notebook, all of which were stored in separated files.\n",
        "\n",
        "Optionally, you may also upload a `coded_descriptions` .csv file containing descriptions for each of the codes in `coded_texts`, which may increase the accuracy of the theme generation. Descriptions were automatically generated for inductive coding with code consistency in the previous notebook. Please ensure that the `coded_descriptions` file matches the `coded_texts` file, i.e. both were generated together using the same LLMCode function.\n",
        "\n",
        "Please upload the files using the file browser on the left and input the file names to the corresponding fields. Make sure to also define your own research question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5YmameiFEPlC"
      },
      "outputs": [],
      "source": [
        "#-------------------------------------------------------\n",
        "#User-defined parameters. You can freely edit the values\n",
        "research_question = 'How do people experience games as art?' # @param {type:\"string\"}\n",
        "coded_texts_file = \"LLMCode/test_data/games_as_art/bopp_test_coded_texts.csv\" # @param {type:\"string\"}\n",
        "code_descriptions_file = \"LLMCode/test_data/games_as_art/bopp_test_code_descriptions.csv\" # @param {type:\"string\"}\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "#Implementation. Only edit this part if you know what your are doing\n",
        "\n",
        "coded_texts_df = pd.read_csv(coded_texts_file).dropna()  # Drop any nan values\n",
        "coded_texts = coded_texts_df.coded_text.tolist()\n",
        "\n",
        "if code_descriptions_file:\n",
        "    code_descriptions_df = pd.read_csv(code_descriptions_file)\n",
        "    code_descriptions = dict(zip(code_descriptions_df.code, code_descriptions_df.description))\n",
        "else:\n",
        "    code_descriptions = None\n",
        "\n",
        "def plot_generated_codes(code_highlights, title):\n",
        "    code_counts = [(code, len(highlights)) for code, highlights in code_highlights.items()]\n",
        "    df_codes = pd.DataFrame(code_counts, columns=['Code', 'Count'])\n",
        "    df_codes = df_codes.sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    # Create a vertical bar plot using Plotly with angled x-axis labels\n",
        "    fig = px.bar(df_codes, x='Code', y='Count', title=title)\n",
        "\n",
        "    # Update layout to angle x-axis labels at 45 degrees\n",
        "    fig.update_layout(xaxis_tickangle=-45)\n",
        "    fig.show()\n",
        "\n",
        "# Parse all codes and highlights in LLM output\n",
        "code_highlights = llmcode.get_codes_and_highlights(coded_texts)\n",
        "plot_generated_codes(code_highlights, 'All codes')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHmgvV_aEPlF"
      },
      "source": [
        "# Theme generation with LLMs: a simple example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGXUWIs51kpV"
      },
      "source": [
        "Before getting into the LLMCode functions, let's first look at a simple example of how an LLM may be prompted to generate themes for a set of codes. In the prompt, we include a set of `example_themes` and the `codes` we would like the system to group under themes. Click \"Show code\" to view the entire prompt. You may also edit the prompt instructions and see what effect this has on the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zuqgAl3GEPlG"
      },
      "outputs": [],
      "source": [
        "#-------------------------------------------------------\n",
        "#User-defined parameters. You can freely edit the values\n",
        "\n",
        "example_themes = \"Appreciation of Craftsmanship and Aesthetics; Interactive Experience and Player Involvement\" # @param {type:\"string\"}\n",
        "codes = \"novelty; player agency; realism; craftsmanship; sacrifice; setting; beauty\"  # @param {type:\"string\"}\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "#Implementation. Feel free to edit the prompt\n",
        "\n",
        "prompt = \"\"\"You are an expert qualitative researcher. You are given a list of qualitative codes at the end of this prompt. Please carry out the following task:\n",
        "- Group these codes into overarching themes.\n",
        "- Assign codes to the themes provided in the list of user-defined themes and generate new themes when needed.\n",
        "- The theme names should be detailed and expressive.\n",
        "- Output a list of Theme objects, containing the theme name and a list of codes that are included in that theme. Start this list with the user-defined themes.\n",
        "- Include each of the codes under exactly one theme.\n",
        "- Give your output as valid JSON.\n",
        "\n",
        "THEME EXAMPLES:\n",
        "{}\n",
        "\n",
        "CODES:\n",
        "{}\n",
        "\"\"\".format(\n",
        "    \"\\n\".join([s.strip() for s in example_themes.split(\";\")]),\n",
        "    \"\\n\".join([s.strip() for s in codes.split(\";\")])\n",
        ")\n",
        "\n",
        "response=llmcode.query_LLM(prompt, model=gpt_model)\n",
        "print(\"LLM output:\\n\")\n",
        "try:\n",
        "    display(Markdown(response))\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2GHwbn6EPlG"
      },
      "source": [
        "# Generating themes with LLMCode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gyh0TfF31q-J"
      },
      "source": [
        "We want the LLM to output data in a structured format, i.e. a list of themes each containing a theme name and a sub-list of codes. The output from LLMs is not always perfect, which means that it is best to use LLMCode's `get_themes()` function for this task that automatically corrects any errors.\n",
        "\n",
        "For example, sometimes, the LLM the may be unable to assign all codes under a theme in one pass. Particularly with long inputs, in this case a potentially lengthy list of codes, the attention mechanism underlying LLMs may not be able to \"focus\" on all of the codes at once. One solution is to solve the task iteratively: we can set the function's `max_retries` parameter to an integer N to make the function repeat the analysis up to N times for the unassigned codes.\n",
        "\n",
        "If you already have some themes in mind, you may write these below in `prior_themes` separated by a semicolon.\n",
        "\n",
        "Here, using the advanced GPT-4o model over smaller models like GPT-4o-mini is recommended due to the complexity of the task. Larger models are able to utilise attention more effectively, and therefore handle a larger amount of input at once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "S4YWk92XEPlH"
      },
      "outputs": [],
      "source": [
        "#-------------------------------------------------------\n",
        "#User-defined parameters. You can freely edit the values\n",
        "\n",
        "prior_themes = \"\" # @param {\"type\":\"string\",\"placeholder\":\"Themes separated by ;\"}\n",
        "max_retries = 3 # @param {\"type\":\"integer\"}\n",
        "gpt_model_for_themes = \"gpt-4o\" # @param [\"gpt-4o-mini\", \"gpt-4o\"]\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "#Implementation. Only edit this part if you know what your are doing\n",
        "\n",
        "prior_themes = [t.strip() for t in prior_themes.split(\";\")] if prior_themes else []\n",
        "codes = set(code_highlights.keys())\n",
        "\n",
        "themes, unthemed_codes = llmcode.get_themes(\n",
        "    codes=codes,\n",
        "    prior_themes=prior_themes,\n",
        "    code_descriptions=code_descriptions,\n",
        "    max_retries=max_retries,\n",
        "    research_question=research_question,\n",
        "    gpt_model=gpt_model_for_themes,\n",
        ")\n",
        "\n",
        "for theme, codes in themes.items():\n",
        "    print(f\"Theme: {theme}\")\n",
        "    print(\"Codes: \" + \"; \".join(codes))\n",
        "    print(\"\")\n",
        "\n",
        "if unthemed_codes:\n",
        "    print(f\"{len(unthemed_codes)} codes weren't assigned a theme: \" + \"; \".join(unthemed_codes))\n",
        "else:\n",
        "    print(\"All codes were assigned a theme.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xat5u4-EPlH"
      },
      "source": [
        "# Communicating the findings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAzMLDb_1w-D"
      },
      "source": [
        "Finally, we take a look at three approaches to communicating the research findings.\n",
        "\n",
        "## Approach 1: Table\n",
        "\n",
        "The first approach, often seen in research papers, involves producing a table of all the identified themes, and for each theme:\n",
        "* the list of included codes;\n",
        "* the number of mentions, calculated as the total count of all highlights across the input texts annotated by any of the included codes; and\n",
        "* example quotations chosen from the highlights: you can choose the number of quotations by changing `quotes_per_theme`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZfoBkSkHEPlH"
      },
      "outputs": [],
      "source": [
        "#-------------------------------------------------------\n",
        "#User-defined parameters. You can freely edit the values\n",
        "\n",
        "quotes_per_theme = 3 # @param {\"type\":\"integer\"}\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "#Implementation. Feel free to edit the prompt\n",
        "\n",
        "def sample_quotes(theme_codes, code_highlights, quotes_per_theme):\n",
        "    all_quotes = list(chain(*(code_highlights[code] for code in theme_codes)))\n",
        "    quotes = random.sample(all_quotes, min(len(all_quotes), quotes_per_theme))\n",
        "    return \"<br>\".join(\"\\\"{}\\\"\".format(quote) for quote in quotes)\n",
        "\n",
        "# Produce table\n",
        "theme_mentions = {theme: sum(len(code_highlights[code]) for code in themes[theme]) for theme in themes}\n",
        "theme_examples = {theme: sample_quotes(themes[theme], code_highlights, quotes_per_theme) for theme in themes}\n",
        "theme_data = [(theme, \"<br>\" .join(codes), theme_mentions[theme], theme_examples[theme]) for theme, codes in themes.items()]\n",
        "df_themes = pd.DataFrame(theme_data, columns=[\"theme\", \"codes\", \"mentions\", \"example quotations\"])\n",
        "df_themes\n",
        "\n",
        "display(HTML(df_themes.to_html(escape=False)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IA04f2f9l3_"
      },
      "source": [
        "## Approach 2: Sunburst chart\n",
        "\n",
        "We might want to communicate the findings in a more visual and interactive manner. One alternative option is to produce a sunburst chart, which is apt for visualising hierarchical data. The inner level visualises the themes and the outer level their associated codes, while the sizes of the segments correspond to the number of mentions for each theme and code. You may hover your mouse over the code segments to reveal a randomly chosen example quotation for each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zsdrzjb0yI3q"
      },
      "outputs": [],
      "source": [
        "#@title Produce sunburst chart\n",
        "\n",
        "code_mentions = {code: len(code_highlights[code]) for theme in themes for code in themes[theme]}\n",
        "code_examples = {code: random.choice(code_highlights[code]) for theme in themes for code in themes[theme]}\n",
        "code_data = [(theme, code, code_mentions[code], code_examples[code]) for theme, codes in themes.items() for code in codes]\n",
        "df_codes = pd.DataFrame(code_data, columns=[\"theme\", \"code\", \"mentions\", \"example quotation\"])\n",
        "\n",
        "# Function to add line breaks to long quotations\n",
        "def format_quotation(quotation, max_length=60):\n",
        "    words = quotation.split()\n",
        "    lines = []\n",
        "    line = \"\"\n",
        "    for word in words:\n",
        "        if len(line) + len(word) + 1 > max_length:\n",
        "            lines.append(line)\n",
        "            line = word\n",
        "        else:\n",
        "            line += \" \" + word if line else word\n",
        "    lines.append(line)  # Add the last line\n",
        "    return \"<br>\".join(lines)\n",
        "\n",
        "# Apply the function to format the quotations\n",
        "df_codes[\"example quotation\"] = df_codes[\"example quotation\"].apply(format_quotation)\n",
        "\n",
        "# Create the sunburst chart with custom data for hover\n",
        "fig = px.sunburst(df_codes, path=['theme', 'code'], values='mentions', title=\"Themes and codes\", hover_data=[\"example quotation\"])\n",
        "\n",
        "# Add custom data (quotations) for hover information\n",
        "fig.update_traces(\n",
        "    hovertemplate='<b>%{label}</b><br>Mentions: %{value}<br>Example quotation: %{customdata[0]}'\n",
        ")\n",
        "\n",
        "# Update layout for larger display\n",
        "fig.update_layout(width=800, height=800)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yde1LI35Wu1j"
      },
      "source": [
        "## Approach 3: LLM-generated research report\n",
        "\n",
        "We can also ask LLMCode to write a report about the findings, using the themes, codes, and quotations as inputs. In academic writing, it is absolutely crucial that the LLM does not make up or \"hallucinate\" incorrect information. The `write_report` function automatically checks for and removes any hallucinated quotations from the output, but it is important for you as a researcher to verify that the findings here reflect your personal insights about the data. What other potential issues do you see with using LLMs to communicate research findings?\n",
        "\n",
        "You may choose the themes for the report yourself or leave `themes_for_report` empty, in which case the four themes with most mentions will be written about.\n",
        "\n",
        "**Choosing the themes yourself**\n",
        "\n",
        "Generating the report takes some time, so if you choose the themes yourself, please specify only up to four themes, separated by a semicolon in `themes_for_report`. Make sure to choose these themes from the LLM-generated themes above. Each chosen theme should have at least three mentions in the input texts, as these will be used to illustrate the themes with quotations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Q7LPCqQaT8p7"
      },
      "outputs": [],
      "source": [
        "#-------------------------------------------------------\n",
        "#User-defined parameters. You can freely edit the values\n",
        "\n",
        "themes_for_report = \"\" # @param {\"type\":\"string\",\"placeholder\":\"Themes separated by ;\"}\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "#Implementation. Only edit this part if you know what your are doing\n",
        "\n",
        "themes_for_report = [t.strip().lower() for t in themes_for_report.split(\";\")] if themes_for_report else None\n",
        "\n",
        "if themes_for_report:\n",
        "    for theme in themes_for_report:\n",
        "        if theme not in [t.lower() for t in themes]:\n",
        "            raise ValueError(\"Theme '{}' not found in the generated themes. Choose from the themes: {}\".format(\n",
        "                theme, \"; \".join(themes.keys())\n",
        "            ))\n",
        "    themes_for_report = {theme: codes for theme, codes in themes.items() if theme.lower() in themes_for_report}\n",
        "else:\n",
        "    themes_for_report = themes\n",
        "\n",
        "report = llmcode.write_report(\n",
        "    themes=themes_for_report,\n",
        "    code_highlights=code_highlights,\n",
        "    max_themes=4,\n",
        "    research_question=research_question,\n",
        "    gpt_model=gpt_model\n",
        ")\n",
        "\n",
        "display(Markdown(report))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
